{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e36302",
   "metadata": {},
   "source": [
    "<h2 align='center'>Codebasics ML Course: ML Flow Tutorial</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295e5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac73cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a6f47",
   "metadata": {},
   "source": [
    "Masing-masing parameter dalam fungsi `make_classification()` dari `sklearn.datasets`:\n",
    "\n",
    "1. **`n_samples=1000`**:\n",
    "   - **Maksud**: Jumlah total **data sampel** (baris) yang akan dibuat.\n",
    "   - **Di sini**: Dataset terdiri dari 1000 sampel (baris).\n",
    "\n",
    "2. **`n_features=10`**:\n",
    "   - **Maksud**: Jumlah total **fitur** (kolom) yang akan dibuat dalam dataset.\n",
    "   - **Di sini**: Dataset akan memiliki 10 fitur (kolom).\n",
    "\n",
    "3. **`n_informative=2`**:\n",
    "   - **Maksud**: Jumlah fitur yang **informatif**, yaitu fitur yang berkontribusi secara langsung dalam menentukan kelas target.\n",
    "   - **Di sini**: Hanya ada 2 fitur yang benar-benar informatif dalam memprediksi output (kelas) dari dataset.\n",
    "\n",
    "4. **`n_redundant=8`**:\n",
    "   - **Maksud**: Jumlah fitur yang **redundan**, yang merupakan kombinasi linier dari fitur informatif.\n",
    "   - **Di sini**: 8 dari 10 fitur adalah redundan, yang berarti mereka adalah hasil dari kombinasi linier dari fitur yang benar-benar informatif.\n",
    "\n",
    "5. **`weights=[0.9, 0.1]`**:\n",
    "   - **Maksud**: Proporsi **kelas target** dalam dataset. `weights` menentukan distribusi kelas untuk klasifikasi biner (dua kelas).\n",
    "   - **Di sini**: 90% sampel berada di kelas 0 (kelas mayoritas), dan 10% sampel berada di kelas 1 (kelas minoritas). Ini menciptakan dataset yang **tidak seimbang**.\n",
    "\n",
    "6. **`flip_y=0`**:\n",
    "   - **Maksud**: Proporsi **label target** yang secara acak akan dibalik, atau dibuat salah, untuk menambahkan **noise** ke dalam data.\n",
    "   - **Di sini**: `flip_y=0` berarti tidak ada label yang di-flip, sehingga tidak ada noise dalam label target.\n",
    "\n",
    "7. **`random_state=42`**:\n",
    "   - **Maksud**: Menetapkan **seed** untuk pembangkitan angka acak, sehingga hasilnya akan selalu sama setiap kali kode dijalankan.\n",
    "   - **Di sini**: `random_state=42` digunakan untuk memastikan **reproducibility**, sehingga setiap kali kamu menjalankan kode ini, kamu akan mendapatkan hasil yang sama.\n",
    "\n",
    "### Penjelasan Umum\n",
    "- Fungsi `make_classification()` digunakan untuk membuat dataset sintetis yang bisa digunakan untuk **klasifikasi**.\n",
    "- Pada contoh ini, kita menghasilkan dataset dengan **1000 sampel**, **10 fitur**, di mana **2 fitur** adalah benar-benar informatif untuk prediksi, dan **8 fitur** lainnya merupakan kombinasi linier dari fitur-fitur informatif tersebut.\n",
    "- **Distribusi kelasnya** tidak seimbang, dengan 90% sampel berada di kelas 0 dan 10% sampel di kelas 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52aa346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset dengan noise (flip_y=0.3)\n",
    "# X_with_noise, y_with_noise = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=3, \n",
    "#                                                  flip_y=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# print(\"\\nDataset dengan noise (flip_y=0.3):\")\n",
    "# print(X_with_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc46b5",
   "metadata": {},
   "source": [
    "flip_y=0.3: Sekitar 30% dari label target akan diubah secara acak menjadi kebalikan dari nilai aslinya, menghasilkan noise dalam dataset. Dalam contoh ini, jika sebelumnya kelas target adalah 0, beberapa di antaranya akan dibalik menjadi 1, dan sebaliknya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0934ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6259bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027f7e0a",
   "metadata": {},
   "source": [
    "### Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df52d46a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468bab4",
   "metadata": {},
   "source": [
    "### Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2742e30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       270\n",
      "           1       0.95      0.70      0.81        30\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.96      0.85      0.89       300\n",
      "weighted avg       0.97      0.97      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18915",
   "metadata": {},
   "source": [
    "### Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3fe3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70bbef1",
   "metadata": {},
   "source": [
    "### Experiment 4: Handle class imbalance using SMOTETomek and then Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecbe6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b931191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       270\n",
      "           1       0.81      0.83      0.82        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.89      0.91      0.90       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac546b4",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Track Experiments Using MLFlow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc788a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\",\n",
    "        {\"C\": 1, \"solver\": \"liblinear\" },\n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        {\"n_estimators\": 10, \"max_depth\": 3, \"random_state\": 42},\n",
    "        RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"},\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"},\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c85de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression',\n",
       "  {'C': 1, 'solver': 'liblinear'},\n",
       "  LogisticRegression(C=1, solver='liblinear'),\n",
       "  (array([[ 1.18673836,  1.51144074,  0.78490373, ..., -0.61229492,\n",
       "           -0.13830257, -0.24753395],\n",
       "          [-1.28810271, -1.03855344, -2.07092052, ...,  0.49607021,\n",
       "           -1.50376955,  0.62474155],\n",
       "          [ 1.66393774,  1.55142135,  2.25024183, ..., -0.69955586,\n",
       "            1.36600648, -0.68290518],\n",
       "          ...,\n",
       "          [ 0.43101615,  0.90013637, -0.42606094, ..., -0.32069604,\n",
       "           -1.01508454,  0.11782042],\n",
       "          [ 0.79839935,  1.5003473 , -0.45098948, ..., -0.54728572,\n",
       "           -1.42140103,  0.11944858],\n",
       "          [ 0.67367695,  1.27538516, -0.39960348, ..., -0.464427  ,\n",
       "           -1.22522394,  0.10635794]]),\n",
       "   array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "          0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "          1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "  (array([[ 0.12763692,  0.53885434, -0.67754938, ..., -0.17119613,\n",
       "           -1.04870039,  0.1959492 ],\n",
       "          [-2.10542071, -1.44658591, -3.8930874 , ...,  0.74058273,\n",
       "           -3.14736801,  1.16957702],\n",
       "          [-0.28933147, -0.48475775,  0.04406009, ...,  0.18182712,\n",
       "            0.35313638, -0.00841763],\n",
       "          ...,\n",
       "          [-0.2028541 , -0.0583418 , -0.53918182, ...,  0.04866874,\n",
       "           -0.52587706,  0.16061758],\n",
       "          [-2.51465752, -1.75645549, -4.59169829, ...,  0.89256429,\n",
       "           -3.68030212,  1.37994004],\n",
       "          [-0.702736  , -0.66487094, -0.93080234, ...,  0.29814829,\n",
       "           -0.55038561,  0.28270309]]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))),\n",
       " ('Random Forest',\n",
       "  {'n_estimators': 10, 'max_depth': 3, 'random_state': 42},\n",
       "  RandomForestClassifier(max_depth=3, n_estimators=10, random_state=42),\n",
       "  (array([[ 1.18673836,  1.51144074,  0.78490373, ..., -0.61229492,\n",
       "           -0.13830257, -0.24753395],\n",
       "          [-1.28810271, -1.03855344, -2.07092052, ...,  0.49607021,\n",
       "           -1.50376955,  0.62474155],\n",
       "          [ 1.66393774,  1.55142135,  2.25024183, ..., -0.69955586,\n",
       "            1.36600648, -0.68290518],\n",
       "          ...,\n",
       "          [ 0.43101615,  0.90013637, -0.42606094, ..., -0.32069604,\n",
       "           -1.01508454,  0.11782042],\n",
       "          [ 0.79839935,  1.5003473 , -0.45098948, ..., -0.54728572,\n",
       "           -1.42140103,  0.11944858],\n",
       "          [ 0.67367695,  1.27538516, -0.39960348, ..., -0.464427  ,\n",
       "           -1.22522394,  0.10635794]]),\n",
       "   array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "          0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "          1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "  (array([[ 0.12763692,  0.53885434, -0.67754938, ..., -0.17119613,\n",
       "           -1.04870039,  0.1959492 ],\n",
       "          [-2.10542071, -1.44658591, -3.8930874 , ...,  0.74058273,\n",
       "           -3.14736801,  1.16957702],\n",
       "          [-0.28933147, -0.48475775,  0.04406009, ...,  0.18182712,\n",
       "            0.35313638, -0.00841763],\n",
       "          ...,\n",
       "          [-0.2028541 , -0.0583418 , -0.53918182, ...,  0.04866874,\n",
       "           -0.52587706,  0.16061758],\n",
       "          [-2.51465752, -1.75645549, -4.59169829, ...,  0.89256429,\n",
       "           -3.68030212,  1.37994004],\n",
       "          [-0.702736  , -0.66487094, -0.93080234, ...,  0.29814829,\n",
       "           -0.55038561,  0.28270309]]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))),\n",
       " ('XGBClassifier',\n",
       "  {'use_label_encoder': False, 'eval_metric': 'logloss'},\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "                n_jobs=None, num_parallel_tree=None, random_state=None, ...),\n",
       "  (array([[ 1.18673836,  1.51144074,  0.78490373, ..., -0.61229492,\n",
       "           -0.13830257, -0.24753395],\n",
       "          [-1.28810271, -1.03855344, -2.07092052, ...,  0.49607021,\n",
       "           -1.50376955,  0.62474155],\n",
       "          [ 1.66393774,  1.55142135,  2.25024183, ..., -0.69955586,\n",
       "            1.36600648, -0.68290518],\n",
       "          ...,\n",
       "          [ 0.43101615,  0.90013637, -0.42606094, ..., -0.32069604,\n",
       "           -1.01508454,  0.11782042],\n",
       "          [ 0.79839935,  1.5003473 , -0.45098948, ..., -0.54728572,\n",
       "           -1.42140103,  0.11944858],\n",
       "          [ 0.67367695,  1.27538516, -0.39960348, ..., -0.464427  ,\n",
       "           -1.22522394,  0.10635794]]),\n",
       "   array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "          0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "          1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "  (array([[ 0.12763692,  0.53885434, -0.67754938, ..., -0.17119613,\n",
       "           -1.04870039,  0.1959492 ],\n",
       "          [-2.10542071, -1.44658591, -3.8930874 , ...,  0.74058273,\n",
       "           -3.14736801,  1.16957702],\n",
       "          [-0.28933147, -0.48475775,  0.04406009, ...,  0.18182712,\n",
       "            0.35313638, -0.00841763],\n",
       "          ...,\n",
       "          [-0.2028541 , -0.0583418 , -0.53918182, ...,  0.04866874,\n",
       "           -0.52587706,  0.16061758],\n",
       "          [-2.51465752, -1.75645549, -4.59169829, ...,  0.89256429,\n",
       "           -3.68030212,  1.37994004],\n",
       "          [-0.702736  , -0.66487094, -0.93080234, ...,  0.29814829,\n",
       "           -0.55038561,  0.28270309]]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))),\n",
       " ('XGBClassifier With SMOTE',\n",
       "  {'use_label_encoder': False, 'eval_metric': 'logloss'},\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "                n_jobs=None, num_parallel_tree=None, random_state=None, ...),\n",
       "  (array([[ 1.18673836,  1.51144074,  0.78490373, ..., -0.61229492,\n",
       "           -0.13830257, -0.24753395],\n",
       "          [-1.28810271, -1.03855344, -2.07092052, ...,  0.49607021,\n",
       "           -1.50376955,  0.62474155],\n",
       "          [ 1.66393774,  1.55142135,  2.25024183, ..., -0.69955586,\n",
       "            1.36600648, -0.68290518],\n",
       "          ...,\n",
       "          [-0.08827578, -0.62434749,  0.97821051, ...,  0.18885517,\n",
       "            1.41672379, -0.28437855],\n",
       "          [ 0.03549707, -0.1123638 ,  0.34255115, ...,  0.02579732,\n",
       "            0.42877693, -0.10060604],\n",
       "          [-0.10496962, -0.11927929, -0.09860757, ...,  0.05012454,\n",
       "           -0.02735928,  0.03041877]]),\n",
       "   array([0, 0, 1, ..., 1, 1, 1])),\n",
       "  (array([[ 0.12763692,  0.53885434, -0.67754938, ..., -0.17119613,\n",
       "           -1.04870039,  0.1959492 ],\n",
       "          [-2.10542071, -1.44658591, -3.8930874 , ...,  0.74058273,\n",
       "           -3.14736801,  1.16957702],\n",
       "          [-0.28933147, -0.48475775,  0.04406009, ...,  0.18182712,\n",
       "            0.35313638, -0.00841763],\n",
       "          ...,\n",
       "          [-0.2028541 , -0.0583418 , -0.53918182, ...,  0.04866874,\n",
       "           -0.52587706,  0.16061758],\n",
       "          [-2.51465752, -1.75645549, -4.59169829, ...,  0.89256429,\n",
       "           -3.68030212,  1.37994004],\n",
       "          [-0.702736  , -0.66487094, -0.93080234, ...,  0.29814829,\n",
       "           -0.55038561,  0.28270309]]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0])))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a827a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params,model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c45308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ef4daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Mich\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Mich\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Mich/MLflow-dagshub\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Mich/MLflow-dagshub\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Mich/MLflow-dagshub initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Mich/MLflow-dagshub initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dagshub setup\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='Mich', repo_name='MLflow-dagshub', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a618626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/10 02:38:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/10 02:38:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic Regression at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0/runs/5b3765f310654bcfbe949440457950f6.\n",
      "2024/10/10 02:38:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0.\n",
      "2024/10/10 02:38:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/10 02:38:46 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0/runs/38a2ce657b4547cb99d3931aecb21bdc.\n",
      "2024/10/10 02:38:46 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0.\n",
      "2024/10/10 02:38:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/10 02:38:54 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0/runs/5e28bdc329bb42a29139c5b3d73dda79.\n",
      "2024/10/10 02:38:54 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0.\n",
      "2024/10/10 02:38:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/10 02:39:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier With SMOTE at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0/runs/4aa6708cd53b4787aa875d5c4bbb3c46.\n",
      "2024/10/10 02:39:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Mich/MLflow-dagshub.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "# If we get an error when running the code for the first time, we need to set the MLFLOW environment variable\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'Mich'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '8d4dcbf356850858a0e926df3b602aa5ae656164'\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/Mich/MLflow-dagshub.mlflow'\n",
    "\n",
    "mlflow.set_experiment(\"Anomaly Detection_Imbalanced Classification\")\n",
    "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.tracking.set_tracking_uri(\"https://dagshub.com/Mich/MLflow-dagshub.mlflow\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        params[\"model_name\"]=model_name\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": report[\"accuracy\"],\n",
    "            \"recall_class_1\": report[\"1\"][\"recall\"],\n",
    "            \"recall_class_0\": report[\"0\"][\"recall\"],\n",
    "            \"f1_score_macro\": report[\"macro avg\"][\"f1-score\"]\n",
    "        })\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, model_name)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5093e5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function log_model in module mlflow.xgboost:\n",
      "\n",
      "log_model(xgb_model, artifact_path, conda_env=None, code_paths=None, registered_model_name=None, signature: mlflow.models.signature.ModelSignature = None, input_example: Union[pandas.core.frame.DataFrame, numpy.ndarray, dict, list, ForwardRef('csr_matrix'), ForwardRef('csc_matrix'), str, bytes, tuple] = None, await_registration_for=300, pip_requirements=None, extra_pip_requirements=None, model_format='xgb', metadata=None, **kwargs)\n",
      "    Log an XGBoost model as an MLflow artifact for the current run.\n",
      "\n",
      "    Args:\n",
      "        xgb_model: XGBoost model (an instance of `xgboost.Booster`_ or models that implement the\n",
      "            `scikit-learn API`_) to be saved.\n",
      "        artifact_path: Run-relative artifact path.\n",
      "        conda_env: Either a dictionary representation of a Conda environment or the path to a conda\n",
      "                   environment yaml file. If provided, this describes the environment this model should be run in.\n",
      "                   At a minimum, it should specify the dependencies contained in :func:`get_default_conda_env()`.\n",
      "                   If ``None``, a conda environment with pip requirements inferred by\n",
      "                   :func:`mlflow.models.infer_pip_requirements` is added\n",
      "                   to the model. If the requirement inference fails, it falls back to using\n",
      "                   :func:`get_default_pip_requirements`. pip requirements from ``conda_env`` are written to a pip\n",
      "                   ``requirements.txt`` file and the full conda environment is written to ``conda.yaml``.\n",
      "                   The following is an *example* dictionary representation of a conda environment::\n",
      "\n",
      "                       {\n",
      "                           \"name\": \"mlflow-env\",\n",
      "                           \"channels\": [\"conda-forge\"],\n",
      "                           \"dependencies\": [\n",
      "                               \"python=3.8.15\",\n",
      "                               {\n",
      "                                   \"pip\": [\n",
      "                                       \"xgboost==x.y.z\"\n",
      "                                   ],\n",
      "                               },\n",
      "                           ],\n",
      "                       }\n",
      "        code_paths: A list of local filesystem paths to Python file dependencies (or directories\n",
      "                    containing file dependencies). These files are *prepended* to the system path when the model\n",
      "                    is loaded. Files declared as dependencies for a given model should have relative\n",
      "                    imports declared from a common root path if multiple files are defined with import dependencies\n",
      "                    between them to avoid import errors when loading the model.\n",
      "\n",
      "                    For a detailed explanation of ``code_paths`` functionality, recommended usage patterns and\n",
      "                    limitations, see the\n",
      "                    `code_paths usage guide <https://mlflow.org/docs/latest/model/dependencies.html?highlight=code_paths#saving-extra-code-with-an-mlflow-model>`_.\n",
      "        registered_model_name: If given, create a model version under\n",
      "            ``registered_model_name``, also creating a registered model if one\n",
      "            with the given name does not exist.\n",
      "        signature: an instance of the :py:class:`ModelSignature <mlflow.models.ModelSignature>`\n",
      "                   class that describes the model's inputs and outputs. If not specified but an\n",
      "                   ``input_example`` is supplied, a signature will be automatically inferred\n",
      "                   based on the supplied input example and model. To disable automatic signature\n",
      "                   inference when providing an input example, set ``signature`` to ``False``.\n",
      "                   To manually infer a model signature, call\n",
      "                   :py:func:`infer_signature() <mlflow.models.infer_signature>` on datasets\n",
      "                   with valid model inputs, such as a training dataset with the target column\n",
      "                   omitted, and valid model outputs, like model predictions made on the training\n",
      "                   dataset, for example:\n",
      "\n",
      "                   .. code-block:: python\n",
      "\n",
      "                       from mlflow.models import infer_signature\n",
      "\n",
      "                       train = df.drop_column(\"target_label\")\n",
      "                       predictions = ...  # compute model predictions\n",
      "                       signature = infer_signature(train, predictions)\n",
      "        input_example: one or several instances of valid model input. The input example is used\n",
      "                       as a hint of what data to feed the model. It will be converted to a Pandas\n",
      "                       DataFrame and then serialized to json using the Pandas split-oriented\n",
      "                       format, or a numpy array where the example will be serialized to json\n",
      "                       by converting it to a list. Bytes are base64-encoded. When the ``signature`` parameter is\n",
      "                       ``None``, the input example is used to infer a model signature.\n",
      "        await_registration_for: Number of seconds to wait for the model version to finish\n",
      "            being created and is in ``READY`` status. By default, the function\n",
      "            waits for five minutes. Specify 0 or None to skip waiting.\n",
      "        pip_requirements: Either an iterable of pip requirement strings\n",
      "                          (e.g. ``[\"xgboost\", \"-r requirements.txt\", \"-c constraints.txt\"]``) or the string path to\n",
      "                          a pip requirements file on the local filesystem (e.g. ``\"requirements.txt\"``). If provided, this\n",
      "                          describes the environment this model should be run in. If ``None``, a default list of requirements\n",
      "                          is inferred by :func:`mlflow.models.infer_pip_requirements` from the current software environment.\n",
      "                          If the requirement inference fails, it falls back to using :func:`get_default_pip_requirements`.\n",
      "                          Both requirements and constraints are automatically parsed and written to ``requirements.txt`` and\n",
      "                          ``constraints.txt`` files, respectively, and stored as part of the model. Requirements are also\n",
      "                          written to the ``pip`` section of the model's conda environment (``conda.yaml``) file.\n",
      "        extra_pip_requirements: Either an iterable of pip\n",
      "                                requirement strings\n",
      "                                (e.g. ``[\"pandas\", \"-r requirements.txt\", \"-c constraints.txt\"]``) or the string path to\n",
      "                                a pip requirements file on the local filesystem (e.g. ``\"requirements.txt\"``). If provided, this\n",
      "                                describes additional pip requirements that are appended to a default set of pip requirements\n",
      "                                generated automatically based on the user's current software environment. Both requirements and\n",
      "                                constraints are automatically parsed and written to ``requirements.txt`` and ``constraints.txt``\n",
      "                                files, respectively, and stored as part of the model. Requirements are also written to the ``pip``\n",
      "                                section of the model's conda environment (``conda.yaml``) file.\n",
      "\n",
      "                                .. warning::\n",
      "                                    The following arguments can't be specified at the same time:\n",
      "\n",
      "                                    - ``conda_env``\n",
      "                                    - ``pip_requirements``\n",
      "                                    - ``extra_pip_requirements``\n",
      "\n",
      "                                `This example <https://github.com/mlflow/mlflow/blob/master/examples/pip_requirements/pip_requirements.py>`_ demonstrates how to specify pip requirements using\n",
      "                                ``pip_requirements`` and ``extra_pip_requirements``.\n",
      "        model_format: File format in which the model is to be saved.\n",
      "        metadata: Custom metadata dictionary passed to the model and stored in the MLmodel file.\n",
      "        kwargs: kwargs to pass to `xgboost.Booster.save_model`_ method.\n",
      "\n",
      "    Returns\n",
      "        A :py:class:`ModelInfo <mlflow.models.model.ModelInfo>` instance that contains the\n",
      "        metadata of the logged model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow.xgboost.log_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c913e",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee2a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = mlflow.register_model(\n",
    "#     \"runs:/d16076a3ec534311817565e6527539c0/sklearn-model\", \"sk-learn-random-forest-reg\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "532b5377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGB-SMOTE_AnomalyDetection'.\n",
      "2024/10/10 02:39:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB-SMOTE_AnomalyDetection, version 1\n",
      "Created version '1' of model 'XGB-SMOTE_AnomalyDetection'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"XGB-SMOTE_AnomalyDetection\"\n",
    "run_id = input(\"Enter Run ID:\")\n",
    "model_uri = f\"runs:/{run_id}/XGBClassifier With SMOTE\" # Same with artifact path when saving the model with mlflow.sklearn.log_model\n",
    "                                    #  mlflow.xgboost.log_model(model, \"model\") -> model_name\n",
    "result = mlflow.register_model(\n",
    "    model_uri,model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea3650",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "Load challenger model and do some testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52677ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"XGB-SMOTE_AnomalyDetection\"\n",
    "model_version = 1\n",
    "# model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model=mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c252038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Anomaly-Detection-Production' already exists. Creating a new version of this model...\n",
      "Copied version '1' of model 'Anomaly-Detection-Model' to version '3' of model 'Anomaly-Detection-Production'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1728502907222, current_stage='None', description='', last_updated_timestamp=1728502907222, name='Anomaly-Detection-Production', run_id='df0c1058bd69433e88a40b4d58759dc7', run_link='', source='models:/Anomaly-Detection-Model/1', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_model_uri = f\"models:/Anomaly-Detection-Model/1\"\n",
    "prod_model = \"Anomaly-Detection-Production\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=dev_model_uri,\n",
    "                          dst_name=prod_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eab3568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri = f\"models:/{prod_model}@champion\"\n",
    "\n",
    "# loaded_model=mlflow.xgboost.load_model(model_uri)\n",
    "loaded_model=mlflow.sklearn.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356c695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonTutEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
